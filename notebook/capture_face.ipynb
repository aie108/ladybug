{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Capture Faces from Scraped Pictures\n",
    "\n",
    "We used haarcascade for frontal face from [OpenCV](https://github.com/opencv/opencv) to capture the frontal faces from the pictures scraped from [My Ladyboy Date](https://myladyboydate.com/) and [Date in Asia](https://www.dateinasia.com/), and cropped them to the 224 by 224 size for input into the model. This resulted in 4,501 girl faces captured out of 6,645 girl profile pictures and 3,157 ladyboy faces captured out of 8,153 ladyboy profile pictures.\n",
    "\n",
    "Girl and Ladyboy pictures are only the first profile pictures on respective dating sites whereas Ladyboy Big are the pictures in the detail section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import math\n",
    "import copy\n",
    "\n",
    "#the usual data science stuff\n",
    "import os,sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "ladyboy_big_input = '../data/ladyboy_big/'\n",
    "ladyboy_big_output = '../data/processed/ladyboy_big/'\n",
    "ladyboy_input = '../data/ladyboy/'\n",
    "ladyboy_output = '../data/processed/ladyboy/'\n",
    "girl_input = '../data/girl/'\n",
    "girl_output = '../data/processed/girl/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cascade_file_src = \"haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascade_file_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ladyboy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#i=0\n",
    "for root, dirs, files in os.walk(ladyboy_input):\n",
    "    for name in files:\n",
    "        #print(i)\n",
    "        #i+=1\n",
    "        imagePath = os.path.join(root, name)\n",
    "\n",
    "        # load image on gray scale :\n",
    "        image = cv2.imread(imagePath)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces in the image :\n",
    "        faces = faceCascade.detectMultiScale(gray, 1.2, 5)\n",
    "\n",
    "        #skip if face not detected\n",
    "        if(len(faces)==0):\n",
    "            continue\n",
    "\n",
    "        #open image\n",
    "        im = Image.open(imagePath)\n",
    "\n",
    "        #get box dimensions\n",
    "        (x, y, w, h) = faces[0]\n",
    "        center_x = x+w/2\n",
    "        center_y = y+h/2\n",
    "        b_dim = min(max(w,h)*1.2,im.width, im.height)\n",
    "        box = (int(center_x-b_dim/2), int(center_y-b_dim/2), \n",
    "               int(center_x+b_dim/2), int(center_y+b_dim/2))\n",
    "        # Crop Image\n",
    "        crpim = im.crop(box).resize((224,224))\n",
    "        #plt.imshow(np.asarray(crpim))\n",
    "        #save file\n",
    "        crpim.save(ladyboy_output+name,format='JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ladyboy Big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#i=0\n",
    "for root, dirs, files in os.walk(ladyboy_big_input):\n",
    "    for name in files:\n",
    "        #print(i)\n",
    "        #i+=1\n",
    "        imagePath = os.path.join(root, name)\n",
    "\n",
    "        # load image on gray scale :\n",
    "        image = cv2.imread(imagePath)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces in the image :\n",
    "        faces = faceCascade.detectMultiScale(gray, 1.2, 5)\n",
    "\n",
    "        #skip if face not detected\n",
    "        if(len(faces)==0):\n",
    "            continue\n",
    "\n",
    "        #open image\n",
    "        im = Image.open(imagePath)\n",
    "\n",
    "        #get box dimensions\n",
    "        (x, y, w, h) = faces[0]\n",
    "        center_x = x+w/2\n",
    "        center_y = y+h/2\n",
    "        b_dim = min(max(w,h)*1.2,im.width, im.height)\n",
    "        box = (int(center_x-b_dim/2), int(center_y-b_dim/2), \n",
    "               int(center_x+b_dim/2), int(center_y+b_dim/2))\n",
    "        # Crop Image\n",
    "        crpim = im.crop(box).resize((224,224))\n",
    "        #plt.imshow(np.asarray(crpim))\n",
    "        #save file\n",
    "        crpim.save(ladyboy_big_output+name,format='JPEG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Girl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#i=0\n",
    "for root, dirs, files in os.walk(girl_input):\n",
    "    for name in files:\n",
    "        #print(i)\n",
    "        #i+=1\n",
    "        imagePath = os.path.join(root, name)\n",
    "\n",
    "        # load image on gray scale :\n",
    "        image = cv2.imread(imagePath)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces in the image :\n",
    "        faces = faceCascade.detectMultiScale(gray, 1.2, 5)\n",
    "\n",
    "        #skip if face not detected\n",
    "        if(len(faces)==0):\n",
    "            continue\n",
    "\n",
    "        #open image\n",
    "        im = Image.open(imagePath)\n",
    "\n",
    "        #get box dimensions\n",
    "        (x, y, w, h) = faces[0]\n",
    "        center_x = x+w/2\n",
    "        center_y = y+h/2\n",
    "        b_dim = min(max(w,h)*1.2,im.width, im.height)\n",
    "        box = (int(center_x-b_dim/2), int(center_y-b_dim/2), \n",
    "               int(center_x+b_dim/2), int(center_y+b_dim/2))\n",
    "        # Crop Image\n",
    "        crpim = im.crop(box).resize((224,224))\n",
    "        #plt.imshow(np.asarray(crpim))\n",
    "        #save file\n",
    "        crpim.save(girl_output+name,format='JPEG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
